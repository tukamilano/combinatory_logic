{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tukamilano/combinatory_logic/blob/main/integer_sequence_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "データを作る部分の軽量化\n",
        "\n",
        "全てのデータをとってきた上でランダムにデータを抽出する(より良い実験をするために)\n",
        "\n",
        "お金を使う"
      ],
      "metadata": {
        "id": "aL9bjrQf6D0c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZG-_fSVZ0H5"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this example, we'll build a sequence-to-sequence Transformer model, which\n",
        "we'll train on an English-to-Spanish machine translation task.\n",
        "\n",
        "You'll learn how to:\n",
        "\n",
        "- Vectorize text using the Keras `TextVectorization` layer.\n",
        "- Implement a `TransformerEncoder` layer, a `TransformerDecoder` layer,\n",
        "and a `PositionalEmbedding` layer.\n",
        "- Prepare data for training a sequence-to-sequence model.\n",
        "- Use the trained model to generate translations of never-seen-before\n",
        "input sentences (sequence-to-sequence inference).\n",
        "\n",
        "The code featured here is adapted from the book\n",
        "[Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition)\n",
        "(chapter 11: Deep learning for text).\n",
        "The present example is fairly barebones, so for detailed explanations of\n",
        "how each building block works, as well as the theory behind Transformers,\n",
        "I recommend reading the book."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywD1ph6JzVbK",
        "outputId": "ae4f7c02-9a5b-43ab-d4ae-47c06d27b97f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys6Z4YuEZ0H5"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty7bI7wBaQaY",
        "outputId": "e8b7410a-8a46-4c16-feba-cff796c9a408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Collecting namex (from keras)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Collecting optree (from keras)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Installing collected packages: namex, optree, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.3.3 namex-0.0.8 optree-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "26F0WVDIZ0H5"
      },
      "outputs": [],
      "source": [
        "# We set the backend to TensorFlow. The code works with\n",
        "# both `tensorflow` and `torch`. It does not work with JAX\n",
        "# due to the behavior of `jax.numpy.tile` in a jit scope\n",
        "# (used in `TransformerDecoder.get_causal_attention_mask()`:\n",
        "# `tile` in JAX does not support a dynamic `reps` argument.\n",
        "# You can make the code work in JAX by wrapping the\n",
        "# inside of the `get_causal_attention_mask` method in\n",
        "# a decorator to prevent jit compilation:\n",
        "# `with jax.ensure_compile_time_eval():`.\n",
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.data as tf_data\n",
        "import tensorflow.strings as tf_strings\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras.layers import TextVectorization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vC80CpaoZ0H7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "def generate_unique_tuples(n):\n",
        "    tuples = set()\n",
        "    while len(tuples) < n:\n",
        "        A1 = random.randint(0, 8)\n",
        "        A2 = random.randint(0, 9)\n",
        "        A3 = random.randint(0, 16)\n",
        "        A4 = random.randint(0, 1)\n",
        "        A5 = random.randint(0, 1)\n",
        "\n",
        "        B1 = random.randint(0, 8)\n",
        "        B2 = random.randint(0, 9)\n",
        "        B3 = random.randint(0, 16)\n",
        "        B4 = random.randint(0, 1)\n",
        "        B5 = random.randint(0, 1)\n",
        "\n",
        "        C = random.randint(0, 1)\n",
        "\n",
        "        tuples.add(((A1, A2, A3, A4, A5),(B1, B2, B3, B4, B5),C))\n",
        "    return list(tuples)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import json\n",
        "import math\n",
        "from operator import add, sub\n",
        "\n",
        "#generator使ったら早くできるかも？\n",
        "def generate_dataset(encoding, length=100):\n",
        "    formula_list = []\n",
        "    evaluated_result = []\n",
        "\n",
        "    T5 = [\"\", \"x!\"]\n",
        "    T4 = [\"\", \"x**x\"]\n",
        "    T3 = [\"\", \"9**x\", \"(-9)**x\", \"8**x\", \"(-8)**x\", \"7**x\", \"(-7)**x\", \"6**x\", \"(-6)**x\", \"5**x\", \"(-5)**x\", \"4**x\", \"(-4)**x\", \"3**x\", \"(-3)**x\", \"2**x\", \"(-2)**x\"]\n",
        "    T2 = [\"\", \"x**9\", \"x**8\", \"x**7\", \"x**6\", \"x**5\", \"x**4\", \"x**3\", \"x**2\", \"x\"]\n",
        "    T1 = [\"\", \"9\", \"8\", \"7\", \"6\", \"5\", \"4\", \"3\", \"2\"]\n",
        "    T0 = [\"+\", \"-\"]\n",
        "\n",
        "    for term_pair in encoding:\n",
        "        A1, A2, A3, A4, A5 = term_pair[0]\n",
        "        B1, B2, B3, B4, B5 = term_pair[1]\n",
        "        C = term_pair[2]\n",
        "\n",
        "        if ((A2, A3, A4, A5) == (0, 0, 0, 0)) or ((B2, B3, B4, B5) == (0, 0, 0, 0)):\n",
        "            continue\n",
        "\n",
        "        a1 = T1[A1]\n",
        "        b1 = T2[A2]\n",
        "        c1 = T3[A3]\n",
        "        d1 = T4[A4]\n",
        "        e1 = T5[A5]\n",
        "\n",
        "        a2 = T1[B1]\n",
        "        b2 = T2[B2]\n",
        "        c2 = T3[B3]\n",
        "        d2 = T4[B4]\n",
        "        e2 = T5[B5]\n",
        "\n",
        "        a0 = T0[C]\n",
        "\n",
        "        first_sequence = a1 + \" \" + b1 + \" \"+ c1 + \" \"+ d1 + \" \" + e1\n",
        "        second_sequence = a2 + \" \" + b2 + \" \"+ c2 + \" \"+ d2 + \" \" + e2\n",
        "\n",
        "        new_first_sequence = ' '.join(first_sequence.split())\n",
        "        first_formula_term = (new_first_sequence.strip()).replace(\" \", \"*\")\n",
        "        first_integer_sequence_term = [eval((first_formula_term.replace(\"x!\", \"math.factorial(x)\")).replace(\"x\", str(i))) for i in range(int(length/2))]\n",
        "\n",
        "        new_second_sequence = ' '.join(second_sequence.split())\n",
        "        second_formula_term = (new_second_sequence.strip()).replace(\" \", \"*\")\n",
        "        second_integer_sequence_term = [eval((second_formula_term.replace(\"x!\", \"math.factorial(x)\")).replace(\"x\", str(i))) for i in range(int(length/2))]\n",
        "\n",
        "        if a0 == \"+\":\n",
        "            evaluated_expr_list = list(map(add, first_integer_sequence_term, second_integer_sequence_term))\n",
        "        else:\n",
        "            evaluated_expr_list = list(map(sub, first_integer_sequence_term, second_integer_sequence_term))\n",
        "\n",
        "        evaluated_expr = (str(evaluated_expr_list)[1:-1].replace(', ', ','))[:length]\n",
        "\n",
        "        formula_term = first_formula_term + a0 + second_formula_term\n",
        "\n",
        "        formula_list.append(formula_term)\n",
        "        evaluated_result.append(evaluated_expr)\n",
        "\n",
        "    return formula_list, evaluated_result\n",
        "\n",
        "encoding = generate_unique_tuples(1000)\n",
        "formula_list, evaluated_result = generate_dataset(encoding)\n",
        "\n",
        "text_pairs = list(zip(evaluated_result, list(map(lambda formula: 'S' + formula + 'E', formula_list))))"
      ],
      "metadata": {
        "id": "IEVHwMqkmOTz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ttJ2UewZ0H7",
        "outputId": "3ea4a8ec-c2ad-4a10-a4c1-0762c4021b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('0,83,-33728,22476042,-18051366912,19375837125000,-26992713122979840,47665763265102630480,-1043634664', 'S5*x**4*4**x*x!-7*x**3*(-9)**x*x**x*x!E')\n",
            "('0,-60,-4032,-157464,11695104,7695324000,3416187778560,1769737688147520,1135299937278689280,896474187', 'S4*x**2*3**x*x**x*x!-8*x**2*9**x*x!E')\n",
            "('0,118,1546240,3726464292,6161734565888,11979707031250000,30971118787340009472,9865369481392962152425', 'S8*x**9*8**x*x**x+6*x**7*9**x*x**x*x!E')\n",
            "('0,-64,266240,-244069200,236370001920,-306302625000000,463348852860026880,-784254623291454510720,1487', 'S2*x**8*(-4)**x*x**x*x!+8*x**8*(-7)**x*x!E')\n",
            "('0,37,1688,69390,3159168,163551000,9573059520,626331308400,45304318402560,3589195696652160,3090358841', 'S3*x**2*7**x*x!+4*x**2*4**x*x!E')\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiobhFXbZ0H7"
      },
      "source": [
        "Now, let's split the sentence pairs into a training set, a validation set,\n",
        "and a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYkr1PcdZ0H8",
        "outputId": "42233c45-8be7-415c-c867-354642c7065d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000000 total pairs\n",
            "700000 training pairs\n",
            "150000 validation pairs\n",
            "150000 test pairs\n"
          ]
        }
      ],
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoZPDaSkZ0H8"
      },
      "source": [
        "## Vectorizing the text data\n",
        "\n",
        "We'll use two instances of the `TextVectorization` layer to vectorize the text\n",
        "data (one for English and one for Spanish),\n",
        "that is to say, to turn the original strings into integer sequences\n",
        "where each integer represents the index of a word in a vocabulary.\n",
        "\n",
        "The English layer will use the default string standardization (strip punctuation characters)\n",
        "and splitting scheme (split on whitespace), while\n",
        "the Spanish layer will use a custom standardization, where we add the character\n",
        "`\"¿\"` to the set of punctuation characters to be stripped.\n",
        "\n",
        "Note: in a production-grade machine translation model, I would not recommend\n",
        "stripping the punctuation characters in either language. Instead, I would recommend turning\n",
        "each punctuation character into its own token,\n",
        "which you could achieve by providing a custom `split` function to the `TextVectorization` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp7o6vUcZ0H8"
      },
      "outputs": [],
      "source": [
        "vocab_size = 19\n",
        "sequence_length = 150\n",
        "batch_size = 64 #適切に変える\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    split='character',\n",
        "    standardize=None,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "spa_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    split='character',\n",
        "    standardize=None,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        ")\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_spa_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "spa_vectorization.adapt(train_spa_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk9maGwpZ0H8"
      },
      "source": [
        "Next, we'll format our datasets.\n",
        "\n",
        "At each training step, the model will seek to predict target words N+1 (and beyond)\n",
        "using the source sentence and the target words 0 to N.\n",
        "\n",
        "As such, the training dataset will yield a tuple `(inputs, targets)`, where:\n",
        "\n",
        "- `inputs` is a dictionary with the keys `encoder_inputs` and `decoder_inputs`.\n",
        "`encoder_inputs` is the vectorized source sentence and `encoder_inputs` is the target sentence \"so far\",\n",
        "that is to say, the words 0 to N used to predict word N+1 (and beyond) in the target sentence.\n",
        "- `target` is the target sentence offset by one step:\n",
        "it provides the next words in the target sentence -- what the model will try to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVHiK-Q-Z0H8"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "def format_dataset(eng, spa):\n",
        "    eng = eng_vectorization(eng)\n",
        "    spa = spa_vectorization(spa)\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": eng,\n",
        "            \"decoder_inputs\": spa[:, :-1],\n",
        "        },\n",
        "        spa[:, 1:],\n",
        "    )\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.cache().shuffle(2048).prefetch(16)\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq3xLoMcZ0H9"
      },
      "source": [
        "Let's take a quick look at the sequence shapes\n",
        "(we have batches of 64 pairs, and all sequences are 20 steps long):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F3rdaqKZ0H9",
        "outputId": "7b1260a0-e871-4a59-e6df-0aece25091bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 150)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 150)\n",
            "targets.shape: (64, 150)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgD_EQMOZ0H9"
      },
      "source": [
        "## Building the model\n",
        "\n",
        "Our sequence-to-sequence Transformer consists of a `TransformerEncoder`\n",
        "and a `TransformerDecoder` chained together. To make the model aware of word order,\n",
        "we also use a `PositionalEmbedding` layer.\n",
        "\n",
        "The source sequence will be pass to the `TransformerEncoder`,\n",
        "which will produce a new representation of it.\n",
        "This new representation will then be passed\n",
        "to the `TransformerDecoder`, together with the target sequence so far (target words 0 to N).\n",
        "The `TransformerDecoder` will then seek to predict the next words in the target sequence (N+1 and beyond).\n",
        "\n",
        "A key detail that makes this possible is causal masking\n",
        "(see method `get_causal_attention_mask()` on the `TransformerDecoder`).\n",
        "The `TransformerDecoder` sees the entire sequences at once, and thus we must make\n",
        "sure that it only uses information from target tokens 0 to N when predicting token N+1\n",
        "(otherwise, it could use information from the future, which would\n",
        "result in a model that cannot be used at inference time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dV6VwSMGZ0H9"
      },
      "outputs": [],
      "source": [
        "import keras.ops as ops\n",
        "\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"dense_dim\": self.dense_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = ops.shape(inputs)[-1]\n",
        "        positions = ops.arange(0, length, 1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        if mask is None:\n",
        "            return None\n",
        "        else:\n",
        "            return ops.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "            padding_mask = ops.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = ops.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = ops.arange(sequence_length)[:, None]\n",
        "        j = ops.arange(sequence_length)\n",
        "        mask = ops.cast(i >= j, dtype=\"int32\")\n",
        "        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = ops.concatenate(\n",
        "            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n",
        "            axis=0,\n",
        "        )\n",
        "        return ops.tile(mask, mult)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"latent_dim\": self.latent_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmcebBOcZ0H9"
      },
      "source": [
        "Next, we assemble the end-to-end model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WF3rm9Z3Z0H-"
      },
      "outputs": [],
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "num_layers = 1  # レイヤー数を指定\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "\n",
        "for _ in range(num_layers):\n",
        "    x = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "\n",
        "encoder_outputs = x\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "\n",
        "for _ in range(num_layers):\n",
        "    x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzdnXHu3Z0H-"
      },
      "source": [
        "## Training our model\n",
        "\n",
        "We'll use accuracy as a quick way to monitor training progress on the validation data.\n",
        "Note that machine translation typically uses BLEU scores as well as other metrics, rather than accuracy.\n",
        "\n",
        "Here we only train for 1 epoch, but to get the model to actually converge\n",
        "you should train for at least 30 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "105TCpIOZ0H-"
      },
      "outputs": [],
      "source": [
        "spa_vocab = spa_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 50\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"S\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        # ops.argmax(predictions[0, i, :]) is not a concrete value for jax here\n",
        "        sampled_token_index = ops.convert_to_numpy(\n",
        "            ops.argmax(predictions[0, i, :])\n",
        "        ).item(0)\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += sampled_token\n",
        "        if sampled_token == \"E\":\n",
        "            break\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spa_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn3tzbf-0sGB",
        "outputId": "dd394ff2-1b2e-4eb5-8a87-d67193aff215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', '*', 'x', '9', '!', 'S', 'E', '-', '8', '5', '7', '4', '3', '2', '6', '+', ')', '(']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9KE_YqIkZ0H-",
        "outputId": "6f152205-d982-4c41-e678-1bcc7275c28c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51,200</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embedding_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,323,570</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │                        │                │ transformer_encoder_1… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m51,200\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m3,155,456\u001b[0m │ positional_embedding_… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)       │      \u001b[38;5;34m5,323,570\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)              │                        │                │ transformer_encoder_1… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,530,226</span> (32.54 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,530,226\u001b[0m (32.54 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,530,226</span> (32.54 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,530,226\u001b[0m (32.54 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10938/10938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 25ms/step - accuracy: 0.9199 - loss: 0.2713 - val_accuracy: 0.8690 - val_loss: 0.4542\n",
            "=====================\n",
            "S3*x**2*9**x*x**x*x!-4*x**2*(-7)**x*x!E\n",
            "S**************************************************\n",
            "=====================\n",
            "Sx**5*9**x*x**x*x!+2*x**3*(-8)**x*x**x*x!E\n",
            "S**************************************************\n",
            "=====================\n",
            "S8*x**6*9**x*x**x*x!+9*x**9*6**x*x!E\n",
            "S**************************************************\n",
            "=====================\n",
            "S7*x**2*9**x*x**x*x!-x**6*x!E\n",
            "S**************************************************\n",
            "=====================\n",
            "S3*x**8*9**x*x**x*x!+6*x**3*5**x*x**xE\n",
            "S**************************************************\n",
            "\u001b[1m10938/10938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 24ms/step - accuracy: 0.8808 - loss: 0.4010 - val_accuracy: 0.9564 - val_loss: 0.1197\n",
            "=====================\n",
            "S6*x**2*9**x*x**x*x!-2*x**3*(-4)**xE\n",
            "S9*x**9*9**x*x**x*x!-9*x**9*(-6)**x*x**x*x!E\n",
            "=====================\n",
            "S3*x**9*9**x*x**x*x!-x**2*6**xE\n",
            "S9*x**9*9**x*x**x*x!-9*x**9*(-6)**x*x**x*x!E\n",
            "=====================\n",
            "S6*x*9**x*x**x*x!-9*x**4*(-2)**x*x!E\n",
            "S9*x**9*9**x*x**x*x!-9*x**9*(-6)**x*x**x*x!E\n",
            "=====================\n",
            "S5*x**6*9**x*x**x*x!+6*x**6*6**x*x**xE\n",
            "S9*x**9*9**x*x**x*x!-9*x**9*(-6)**x*x**x*x!E\n",
            "=====================\n",
            "S5*x**5*9**x*x**x*x!+x**5E\n",
            "S9*x**9*9**x*x**x*x!-9*x**9*(-6)**x*x**x*x!E\n",
            "\u001b[1m10938/10938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 24ms/step - accuracy: 0.9566 - loss: 0.1171 - val_accuracy: 0.9614 - val_loss: 0.0999\n",
            "=====================\n",
            "S8*x**5*9**x*x**x*x!-3*x**9*(-9)**x*x!E\n",
            "S9*x**4*9**x*x**x*x!-2*x**2*(-9)**x*x**x*x!E\n",
            "=====================\n",
            "S5*x**8*9**x*x**x*x!-2*x*(-3)**xE\n",
            "S9*x**4*9**x*x**x*x!-2*x**2*(-9)**x*x**x*x!E\n",
            "=====================\n",
            "Sx**9*9**x*x**x*x!+8*x**3*(-3)**x*x!E\n",
            "S9*x**4*9**x*x**x*x!-2*x**2*(-9)**x*x**x*x!E\n",
            "=====================\n",
            "S3*x**4*9**x*x**x*x!-3*x**2*5**xE\n",
            "S9*x**4*9**x*x**x*x!-2*x**2*(-9)**x*x**x*x!E\n",
            "=====================\n",
            "S4*x**7*9**x*x**x*x!+x**7*9**x*x!E\n",
            "S9*x**4*9**x*x**x*x!-2*x**2*(-9)**x*x**x*x!E\n",
            "\u001b[1m10938/10938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 24ms/step - accuracy: 0.9555 - loss: 0.1128 - val_accuracy: 0.9506 - val_loss: 0.1188\n",
            "=====================\n",
            "S8*x**5*9**x*x**x*x!-2*x**9*(-5)**x*x**x*x!E\n",
            "Sx**5*9**x*x**x*x!+x*x**9*(-8)**x*x**x*x!E\n",
            "=====================\n",
            "S4*x**6*9**x*x**x*x!+7*x**2*7**x*x**xE\n",
            "Sx**5*9**x*x**x*x!+x*x**9*(-8)**x*x**x*x!E\n",
            "=====================\n",
            "S6*x**7*9**x*x**x*x!+7*2**x*x!E\n",
            "S9*x**8*x*x*x*x*x*x!-8**8*x*x**x!E\n",
            "=====================\n",
            "S9*x**6*9**x*x**x*x!-4*x**7*(-8)**xE\n",
            "Sx**5*9**x*x**x*x!+x*x**9*(-8)**x*x**x*x!E\n",
            "=====================\n",
            "S3*x**6*9**x*x**x*x!+3*x**5*(-8)**xE\n",
            "Sx**5*9**x*x**x*x!+x*x**9*(-8)**x*x**x*x!E\n",
            "\u001b[1m10938/10938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 24ms/step - accuracy: 0.9520 - loss: 0.1176 - val_accuracy: 0.9572 - val_loss: 0.1001\n",
            "=====================\n",
            "S4*x**9*9**x*x**x*x!+8*x**2*(-2)**x*x**x*x!E\n",
            "S3*x**8*x**x*x**x*x!+3*x**3*(-3)**x*x**x*x!E\n",
            "=====================\n",
            "S9*x**9*9**x*x**x*x!+6*x**6*(-2)**x*x!E\n",
            "S3*x**9*x**x*x**x*x!+x**9*(-8)**x*x**x*x!E\n",
            "=====================\n",
            "S9*x**6*9**x*x**x*x!-3*(-2)**x*x!E\n",
            "S9*x**8*x**x*x**x*x!-5*(-8)**x*x**x*x!E\n",
            "=====================\n",
            "S9*x**6*9**x*x**x*x!-5*x**3*6**x*x**xE\n",
            "S3*x**8*x**x*x**x*x!+3*x**3*(-3)**x*x**x*x!E\n",
            "=====================\n",
            "S8*x*9**x*x**x*x!+x*7**x*x!E\n",
            "S3*x**8*x**x*x**x*x!+3*x**3*(-3)**x*x**x*x!E\n",
            "\u001b[1m10938/10938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 24ms/step - accuracy: 0.9574 - loss: 0.1016 - val_accuracy: 0.9615 - val_loss: 0.0954\n",
            "=====================\n",
            "S5*x**4*9**x*x**x*x!+8*x**2*5**x*x!E\n",
            "S9*x**6*9**x*x**x*x!-6*x**6*(-9)**x*x**x*x!E\n",
            "=====================\n",
            "S3*x**3*9**x*x**x*x!+3*x**4*(-9)**xE\n",
            "S9*x**6*9**x*x**x*x!-6*x**6*(-9)**x*x**x*x!E\n",
            "=====================\n",
            "S9*x**4*9**x*x**x*x!-8*x**5*(-9)**xE\n",
            "S9*x**6*9**x*x**x*x!-6*x**6*(-9)**x*x**x*x!E\n",
            "=====================\n",
            "S7*x**8*9**x*x**x*x!+9*x**8*(-4)**x*x**x*x!E\n",
            "S9*x**6*9**x*x**x*x!-6*x**6*(-9)**x*x**x*x!E\n",
            "=====================\n",
            "Sx**9*9**x*x**x*x!-x**5*(-8)**x*x**x*x!E\n",
            "S8*x**6*9**x*x**x*x!-6*x**6*(-9)**x*x**xE\n",
            "\u001b[1m10938/10938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 24ms/step - accuracy: 0.9611 - loss: 0.0969 - val_accuracy: 0.9615 - val_loss: 0.0933\n",
            "=====================\n",
            "S6*x**3*9**x*x**x*x!+7*x**7*(-2)**xE\n",
            "Sx**7*9*x*x*x*x*x!-5**x**x*x*x*x!E\n",
            "=====================\n",
            "S3*x*9**x*x**x*x!+9*x**4*2**x*x!E\n",
            "Sx**7*9*x*x*x*x*x!-5**x**x*x*x*x!E\n",
            "=====================\n",
            "S5*x**7*9**x*x**x*x!+3*x**4*(-7)**x*x!E\n",
            "Sx**7*9*x*x*x*x*x!-4**x**x*x*x*x**x*x!E\n",
            "=====================\n",
            "S8*x**4*9**x*x**x*x!+6*x**6*(-5)**x*x!E\n",
            "Sx**7*9*x*x*x*x*x!-4**x**x*x*x*x**x*x!E\n",
            "=====================\n",
            "Sx**9*9**x*x**x*x!-x**6*8**x*x**x*x!E\n",
            "Sx**7*9*x*x*x*x*x!-5**x**x*x*x*x!E\n",
            "\u001b[1m10938/10938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 24ms/step - accuracy: 0.9617 - loss: 0.0942 - val_accuracy: 0.9606 - val_loss: 0.1067\n",
            "=====================\n",
            "S7*x**4*9**x*x**x*x!-4*x**9*(-4)**x*x**x*x!E\n",
            "S8*x**2*9**x*x**x*x!+8*x**2*(-8)**x*x**x*x!E\n",
            "=====================\n",
            "S9*x**9*9**x*x**x*x!+3*x**2*4**xE\n",
            "S6*x**2*9**x*x**x*x!+8*x**2*(-8)**x*x**x*x!E\n",
            "=====================\n",
            "S4*x**9*9**x*x**x*x!-x**4*5**x*x**x*x!E\n",
            "S8*x**9*9**x*x**x*x!+8*x**2*(-8)**x*x**x*x!E\n",
            "=====================\n",
            "S9*x*9**x*x**x*x!-4*x**9*7**xE\n",
            "S6*x**2*9**x*x**x*x!+8*x**2*(-8)**x*x**x*x!E\n",
            "=====================\n",
            "S8*x**4*9**x*x**x*x!-2*x**7*9**x*x**xE\n",
            "S8*x**2*9**x*x**x*x!+8*x**2*(-8)**x*x**x*x!E\n",
            "\u001b[1m10938/10938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 24ms/step - accuracy: 0.9625 - loss: 0.0947 - val_accuracy: 0.9640 - val_loss: 0.0916\n",
            "=====================\n",
            "S9*x**2*9**x*x**x*x!-8*x**5E\n",
            "S7*x**9*9**x*x**x*x!+2*x**2*(-2)**x*x**xE\n",
            "=====================\n",
            "S5*x**6*9**x*x**x*x!-2*x**2*(-5)**x*x**x*x!E\n",
            "S5*x**9*9**x*x**x*x!+5*x**2*(-2)**x*x**xE\n",
            "=====================\n",
            "S3*x**3*9**x*x**x*x!-3*2**xE\n",
            "S2*x**7*9**x*x**x*x!-8*(-9)**x*x**xE\n",
            "=====================\n",
            "S9*x**3*9**x*x**x*x!-6*(-6)**x*x!E\n",
            "S2*x**6*9**x*x**x*x!-8*(-9)**x*x**xE\n",
            "=====================\n",
            "Sx**5*9**x*x**x*x!+7*x*(-9)**x*x**xE\n",
            "Sx**7*9**x*x**x*x!-9*x**2*(-8)**x*x**x*x!E\n",
            "\u001b[1m10938/10938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 24ms/step - accuracy: 0.9637 - loss: 0.0921 - val_accuracy: 0.9668 - val_loss: 0.0846\n",
            "=====================\n",
            "S9*9**x*x**x*x!+4*x**5*(-3)**x*x!E\n",
            "S9*9**x*x**x*x!+x**(-2)**x*x!E\n",
            "=====================\n",
            "S2*x*9**x*x**x*x!+9*x**5*3**xE\n",
            "Sx**2*9**x*x**x*x!+6*x**9*(-3)**x*x**xE\n",
            "=====================\n",
            "S8*x**8*9**x*x**x*x!-5*x*(-7)**x*x**xE\n",
            "S7*x**9*9**x*x**x*x!-x*x**x*x**x*x!E\n",
            "=====================\n",
            "Sx**2*9**x*x**x*x!+9*x**6*(-2)**xE\n",
            "Sx**2*9**x*x**x*x!+9*x**8*(-9)**x*x**xE\n",
            "=====================\n",
            "S5*x**8*9**x*x**x*x!+4*(-5)**xE\n",
            "S9*x**8*9**x*x**x*x!+3*(-2)**x*x**x*x!E\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "spa_vocab = spa_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 50\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"S\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        # ops.argmax(predictions[0, i, :]) is not a concrete value for jax here\n",
        "        sampled_token_index = ops.convert_to_numpy(\n",
        "            ops.argmax(predictions[0, i, :])\n",
        "        ).item(0)\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += sampled_token\n",
        "        if sampled_token == \"E\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "transformer.summary() #adam\n",
        "transformer.compile(\n",
        "    \"adamW\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "for i in range(epochs):\n",
        "    transformer.fit(train_ds, epochs=1, validation_data=val_ds)\n",
        "    for _ in range(5):\n",
        "        print(\"=====================\")\n",
        "        input_output_sentence = random.choice(test_pairs)\n",
        "        translated = decode_sequence(input_output_sentence[0])\n",
        "        print(input_output_sentence[1])\n",
        "        print(translated)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}